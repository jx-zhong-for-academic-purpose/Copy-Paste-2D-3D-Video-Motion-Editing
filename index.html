<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy & Paste 2D-3D Features for Video Motion Editing | AAAI 2026</title>
    
    <!-- Meta tags for SEO -->
    <meta name="description" content="AAAI 2026: Video-to-video human motion editing using collaborative 2D-3D feature fusion">
    <meta name="keywords" content="video editing, motion transfer, diffusion models, AAAI, computer vision">
    <meta property="og:title" content="Copy & Paste 2D-3D Features for Video Motion Editing">
    <meta property="og:description" content="Official project page for AAAI 2026 paper">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 50px 0 40px;
            text-align: center;
        }
        
        h1 {
            font-size: 2.2em;
            margin-bottom: 25px;
            font-weight: 700;
            line-height: 1.3;
        }
        
        .authors {
            font-size: 1.15em;
            margin-bottom: 12px;
            line-height: 1.8;
        }
        
        .authors span {
            display: inline-block;
            margin: 0 8px;
        }
        
        .affiliation {
            font-size: 1em;
            opacity: 0.95;
            margin-bottom: 25px;
        }
        
        .conference-tag {
            display: inline-block;
            background: rgba(255,255,255,0.25);
            padding: 8px 20px;
            border-radius: 20px;
            font-size: 1.1em;
            font-weight: 600;
            margin-bottom: 30px;
            backdrop-filter: blur(10px);
        }
        
        .links {
            display: flex;
            gap: 12px;
            justify-content: center;
            flex-wrap: wrap;
            margin-top: 25px;
        }
        
        .btn {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 10px 24px;
            background: white;
            color: #667eea;
            text-decoration: none;
            border-radius: 20px;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 2px 8px rgba(0,0,0,0.15);
        }
        
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }
        
        .btn svg {
            width: 18px;
            height: 18px;
        }
        
        section {
            background: white;
            margin: 30px 0;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        
        h2 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 1.8em;
            padding-bottom: 10px;
            border-bottom: 2px solid #667eea;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        .figure {
            text-align: center;
            margin: 30px 0;
        }
        
        .figure img {
            max-width: 100%;
            height: auto;
            border-radius: 6px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        .figure-caption {
            margin-top: 12px;
            font-style: italic;
            color: #666;
            font-size: 0.95em;
        }
        
        .video-wrapper {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 比例 */
            height: 0;
            overflow: hidden;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        .video-wrapper iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .stat-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
        }
        
        .stat-number {
            font-size: 2.5em;
            font-weight: 700;
            margin-bottom: 8px;
        }
        
        .stat-label {
            font-size: 1em;
            opacity: 0.95;
        }
        
        /* ==================== 对比表格 ==================== */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        
        th {
            background: #667eea;
            color: white;
            font-weight: 600;
        }
        
        tr:hover {
            background: #f5f5f5;
        }
        
        .bibtex {
            background: #f8f8f8;
            border-left: 4px solid #667eea;
            padding: 20px;
            border-radius: 4px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            margin: 20px 0;
        }
        
        .bibtex pre {
            margin: 0;
            white-space: pre-wrap;
        }
        
        footer {
            text-align: center;
            padding: 30px 0;
            color: #666;
            font-size: 0.95em;
        }
        
        @media (max-width: 768px) {
            h1 {
                font-size: 1.6em;
            }
            
            .authors {
                font-size: 1em;
            }
            
            section {
                padding: 25px 20px;
            }
            
            .links {
                flex-direction: column;
                align-items: center;
            }
            
            .btn {
                width: 80%;
                justify-content: center;
            }
        }
        
        .highlight-box {
            background: #f0f7ff;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 4px;
        }
        
        .highlight-box strong {
            color: #667eea;
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Collaboratively "Copy & Paste" 2D–3D Features for<br>Complex Video-to-Video Motion Editing</h1>
            
            <div class="authors">
                <span>Jia-Xing Zhong<sup>1*</sup></span>
                <span>Shijie Zhao<sup>1✉</sup></span>
                <span>Junlin Li<sup>1</sup></span>
                <span>Li Zhang<sup>1</sup></span>
            </div>
            
            <div class="affiliation">
                <sup>1</sup>ByteDance Inc.<br>
                <sup>*</sup>Work done during internship &nbsp;&nbsp; <sup>✉</sup>Corresponding author
            </div>
            
            <div class="conference-tag">
                AAAI 2026
            </div>
            
            <div class="links">
                <a href="assets/paper.pdf" class="btn" target="_blank">
                    <svg fill="currentColor" viewBox="0 0 20 20"><path d="M9 2a2 2 0 00-2 2v8a2 2 0 002 2h6a2 2 0 002-2V6.414A2 2 0 0016.414 5L14 2.586A2 2 0 0012.586 2H9z"></path><path d="M3 8a2 2 0 012-2v10h8a2 2 0 01-2 2H5a2 2 0 01-2-2V8z"></path></svg>
                    Paper
                </a>
                <a href="assets/supplementary.pdf" class="btn" target="_blank">
                    <svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M4 4a2 2 0 012-2h4.586A2 2 0 0112 2.586L15.414 6A2 2 0 0116 7.414V16a2 2 0 01-2 2H6a2 2 0 01-2-2V4z" clip-rule="evenodd"></path></svg>
                    Supplementary
                </a>
                <a href="https://arxiv.org/abs/XXXX.XXXXX" class="btn" target="_blank">
                    <svg fill="currentColor" viewBox="0 0 20 20"><path d="M10 18a8 8 0 100-16 8 8 0 000 16zm1-11a1 1 0 10-2 0v2H7a1 1 0 100 2h2v2a1 1 0 102 0v-2h2a1 1 0 100-2h-2V7z"></path></svg>
                    arXiv
                </a>
                <a href="#dataset" class="btn">
                    <svg fill="currentColor" viewBox="0 0 20 20"><path d="M3 12v3c0 1.657 3.134 3 7 3s7-1.343 7-3v-3c0 1.657-3.134 3-7 3s-7-1.343-7-3z"></path><path d="M3 7v3c0 1.657 3.134 3 7 3s7-1.343 7-3V7c0 1.657-3.134 3-7 3S3 8.657 3 7z"></path><path d="M17 5c0 1.657-3.134 3-7 3S3 6.657 3 5s3.134-3 7-3 7 1.343 7 3z"></path></svg>
                    Dataset
                </a>
            </div>
        </div>
    </header>

    <div class="container">
        <!-- ==================== Teaser ==================== -->
        <section>
            <div class="figure">
                <img src="assets/images/teaser.png" alt="Method Overview">
                <p class="figure-caption">
                    Our method handles complex video-to-video motion editing scenarios including 
                    location changes, orientation variations, and complicated non-upright poses 
                    from rhythmic gymnastics and figure skating.
                </p>
            </div>
        </section>

        <!-- ==================== Abstract ==================== -->
        <section>
            <h2>Abstract</h2>
            <p>
                The task of video-to-video human motion editing aims to transfer motion from a specific 
                video to a reference video while preserving the background dynamics and the original 
                protagonist's appearance. From analysis, we identify critical limitations in existing 
                models that fail to capture the full complexity of human motions, particularly regarding:
            </p>
            <div class="highlight-box">
                <strong>(1) Location changes</strong> - Large-scale position variations, especially in depth<br>
                <strong>(2) Orientation variations</strong> - Substantial rotations and viewing angle changes<br>
                <strong>(3) Complicated non-upright poses</strong> - Complex movements deviating from standard postures
            </div>
            <p>
                To address these challenges, we propose a framework that selectively "copies and pastes" 
                2D and 3D features across spatio-temporal dimensions into a shared representation space 
                for motion guidance. This is achieved through: <strong>(1)</strong> a mutual distillation 
                mechanism that enhances the robustness and capability of individual encoders, and 
                <strong>(2)</strong> a selective fusion module that adaptively weights and combines 
                complementary information from spatio-temporal representations.
            </p>
        </section>

        <!-- ==================== Method ==================== -->
        <section>
            <h2>Method Overview</h2>
            <div class="figure">
                <img src="assets/images/method.png" alt="Method Architecture">
                <p class="figure-caption">
                    Our framework comprises mutual distillation between 2D and 3D encoders, 
                    followed by selective fusion that adaptively combines complementary features.
                </p>
            </div>
            
            <h3 style="color: #667eea; margin: 30px 0 15px;">Key Contributions</h3>
            <ul style="line-height: 2; margin-left: 20px;">
                <li><strong>Dual Guidance Integration:</strong> First work to utilize both 2D and 3D information for video-to-video motion editing</li>
                <li><strong>Mutual Distillation:</strong> Enhances individual encoder robustness through alternating optimization</li>
                <li><strong>Selective Fusion:</strong> Adaptively weights and combines features across spatio-temporal dimensions</li>
                <li><strong>Challenging Dataset:</strong> 130 clips from gymnastics and figure skating with complex motions</li>
            </ul>
        </section>

        <!-- ==================== Results ==================== -->
        <section>
            <h2>Results</h2>
            <p>
                Our method significantly outperforms existing approaches, particularly in handling 
                complex human motions involving orientation changes, location variations, and non-upright poses.
            </p>
            
            <h3 style="color: #667eea; margin: 25px 0 15px;">Quantitative Comparison</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>L1 ↓</th>
                        <th>SSIM ↑</th>
                        <th>LPIPS ↓</th>
                        <th>FID ↓</th>
                        <th>FVD ↓</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>MagicAnimate</td>
                        <td>1.47E-04</td>
                        <td>0.71</td>
                        <td>0.47</td>
                        <td>55.67</td>
                        <td>467.89</td>
                    </tr>
                    <tr>
                        <td>Champ</td>
                        <td>1.01E-04</td>
                        <td>0.73</td>
                        <td>0.41</td>
                        <td>48.12</td>
                        <td>401.23</td>
                    </tr>
                    <tr>
                        <td>MotionEditor</td>
                        <td>1.12E-04</td>
                        <td>0.73</td>
                        <td>0.45</td>
                        <td>51.37</td>
                        <td>428.77</td>
                    </tr>
                    <tr style="background: #f0f7ff; font-weight: 600;">
                        <td><strong>Ours</strong></td>
                        <td><strong>6.72E-05</strong></td>
                        <td><strong>0.78</strong></td>
                        <td><strong>0.31</strong></td>
                        <td><strong>37.25</strong></td>
                        <td><strong>358.67</strong></td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- ==================== Dataset ==================== -->
        <section id="dataset">
            <h2>Evaluation Dataset</h2>
            <p>
                We introduce a comprehensive evaluation dataset featuring complex human motions from 
                <strong>rhythmic gymnastics</strong> and <strong>figure skating</strong> competitions. 
                This dataset addresses critical gaps in existing benchmarks by encompassing significant 
                spatial movement, orientation changes, and intricate poses.
            </p>
            <p style="margin-top: 15px;">
                The dataset will be made publicly available upon paper publication, including:
            </p>
            <ul style="line-height: 2; margin: 15px 0 15px 30px;">
                <li>130 high-quality video clips from professional competitions</li>
                <li>Extracted 2D pose annotations (using DWPose)</li>
                <li>Rendered 3D guidance maps (depth, normal, dense pose)</li>
                <li>Human masks and metadata</li>
            </ul>
            
            <div class="stats">
                <div class="stat-box">
                    <div class="stat-number">130</div>
                    <div class="stat-label">Video Clips</div>
                </div>
                <div class="stat-box">
                    <div class="stat-number">30 fps</div>
                    <div class="stat-label">Frame Rate</div>
                </div>
                <div class="stat-box">
                    <div class="stat-number">512×512</div>
                    <div class="stat-label">Resolution</div>
                </div>
                <div class="stat-box">
                    <div class="stat-number">25-569</div>
                    <div class="stat-label">Frames/Clip</div>
                </div>
            </div>
            
            <div style="text-align: center; margin-top: 30px;">
                <a href="https://github.com/jx-zhong-for-academic-purpose/Copy-Paste-2D-3D-Video-Motion-Editing/releases" class="btn" target="_blank">
                    <svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M3 17a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm3.293-7.707a1 1 0 011.414 0L9 10.586V3a1 1 0 112 0v7.586l1.293-1.293a1 1 0 111.414 1.414l-3 3a1 1 0 01-1.414 0l-3-3a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg>
                    Download Dataset
                </a>
            </div>
        </section>

        <!-- ==================== Citation ==================== -->
        <section>
            <h2>Citation</h2>
            <p>If you find our work useful, please consider citing:</p>
            <div class="bibtex">
<pre>@inproceedings{zhong2026copy,
  title={Collaboratively "Copy & Paste" 2D-3D Features for 
         Complex Video-to-Video Motion Editing},
  author={Zhong, Jia-Xing and Zhao, Shijie and Li, Junlin and Zhang, Li},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2026}
}</pre>
            </div>
        </section>

        <!-- ==================== Acknowledgments ==================== -->
        <section>
            <h2>Acknowledgments</h2>
            <p>
                This work was conducted at ByteDance Inc. We thank the reviewers for their valuable 
                feedback and suggestions.
            </p>
        </section>
    </div>

    <footer>
        <div class="container">
            <p>&copy; 2026 ByteDance Inc. All rights reserved.</p>
            <p style="margin-top: 10px;">
                Contact: <a href="mailto:jxzhong@pku.edu.cn" style="color: #667eea;">jxzhong@pku.edu.cn</a>
            </p>
        </div>
    </footer>
</body>
</html>
